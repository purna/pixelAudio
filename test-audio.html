<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Test - PixelAudio</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background: #1a1a2e;
            color: #e0e7ff;
        }
        .test-section {
            background: #16213e;
            padding: 20px;
            margin: 20px 0;
            border-radius: 10px;
            border: 1px solid #00ff41;
        }
        button {
            background: #00ff41;
            color: #1a1a2e;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            margin: 5px;
            cursor: pointer;
            font-weight: bold;
        }
        button:hover {
            background: #00cc35;
        }
        .status {
            margin-top: 10px;
            padding: 10px;
            border-radius: 5px;
        }
        .success {
            background: #10b981;
            color: white;
        }
        .error {
            background: #ef4444;
            color: white;
        }
        .info {
            background: #3b82f6;
            color: white;
        }
    </style>
</head>
<body>
    <h1>üéµ PixelAudio Test Page</h1>
    <p>This page tests the audio functionality fixes:</p>

    <div class="test-section">
        <h3>üîä Audio Context Test</h3>
        <p>Tests if the AudioContext can be created and resumed properly.</p>
        <button onclick="testAudioContext()">Test Audio Context</button>
        <div id="audioContextResult" class="status"></div>
    </div>

    <div class="test-section">
        <h3>üéº Sound Generation Test</h3>
        <p>Tests basic sound generation without the full UI.</p>
        <button onclick="testSoundGeneration()">Test Sound Generation</button>
        <div id="soundGenResult" class="status"></div>
    </div>

    <div class="test-section">
        <h3>‚èØÔ∏è Playback Test</h3>
        <p>Tests if audio can be played back properly.</p>
        <button onclick="testPlayback()">Test Playback</button>
        <div id="playbackResult" class="status"></div>
    </div>

    <div class="test-section">
        <h3>üìÅ File Export Test</h3>
        <p>Tests if WAV files can be created and downloaded.</p>
        <button onclick="testWavExport()">Test WAV Export</button>
        <div id="wavResult" class="status"></div>
    </div>

    <div class="test-section">
        <h3>üîó Open Main Application</h3>
        <p>Open the main PixelAudio application to test all features:</p>
        <button onclick="window.open('index.html', '_blank')">Open PixelAudio</button>
    </div>

    <script>
        let audioContext = null;
        let testBuffer = null;

        async function testAudioContext() {
            const result = document.getElementById('audioContextResult');
            result.className = 'status info';
            result.textContent = 'Testing AudioContext...';

            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                result.className = 'status success';
                result.textContent = `‚úÖ AudioContext created and resumed! State: ${audioContext.state}, Sample Rate: ${audioContext.sampleRate}Hz`;
                
                // Generate test buffer
                await generateTestBuffer();
                
            } catch (error) {
                result.className = 'status error';
                result.textContent = `‚ùå AudioContext error: ${error.message}`;
            }
        }

        async function generateTestBuffer() {
            if (!audioContext) return;

            const sampleRate = audioContext.sampleRate;
            const duration = 0.5; // 0.5 seconds
            const samples = Math.floor(duration * sampleRate);
            
            testBuffer = audioContext.createBuffer(1, samples, sampleRate);
            const data = testBuffer.getChannelData(0);
            
            // Generate a simple sine wave at 440Hz
            for (let i = 0; i < samples; i++) {
                const t = i / sampleRate;
                data[i] = Math.sin(2 * Math.PI * 440 * t) * Math.exp(-t * 3); // Decay envelope
            }
        }

        function testSoundGeneration() {
            const result = document.getElementById('soundGenResult');
            result.className = 'status info';
            result.textContent = 'Testing sound generation...';

            try {
                if (!testBuffer) {
                    throw new Error('No test buffer available. Run Audio Context test first.');
                }

                result.className = 'status success';
                result.textContent = `‚úÖ Sound generation working! Buffer: ${testBuffer.length} samples, Duration: ${testBuffer.duration}s`;
                
            } catch (error) {
                result.className = 'status error';
                result.textContent = `‚ùå Sound generation error: ${error.message}`;
            }
        }

        async function testPlayback() {
            const result = document.getElementById('playbackResult');
            result.className = 'status info';
            result.textContent = 'Testing playback...';

            try {
                if (!testBuffer || !audioContext) {
                    throw new Error('No audio context or buffer available. Run previous tests first.');
                }

                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }

                const source = audioContext.createBufferSource();
                source.buffer = testBuffer;
                source.connect(audioContext.destination);
                source.start();

                result.className = 'status success';
                result.textContent = '‚úÖ Playback started! You should hear a 440Hz tone.';
                
                source.onended = () => {
                    result.textContent = '‚úÖ Playback completed!';
                };

            } catch (error) {
                result.className = 'status error';
                result.textContent = `‚ùå Playback error: ${error.message}`;
            }
        }

        function bufferToWave(buffer, len) {
            const numChannels = buffer.numberOfChannels;
            const sampleRate = buffer.sampleRate;
            const format = 1; // PCM
            const bitDepth = 16;

            const bytesPerSample = bitDepth / 8;
            const blockAlign = numChannels * bytesPerSample;

            const data = new Int16Array(len * numChannels);
            const channelData = buffer.getChannelData(0);
            
            for (let i = 0; i < len; i++) {
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                data[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
            }

            const dataLength = data.length * bytesPerSample;
            const arrayBuffer = new ArrayBuffer(44 + dataLength);
            const view = new DataView(arrayBuffer);

            // RIFF chunk descriptor
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + dataLength, true);
            writeString(view, 8, 'WAVE');

            // FMT sub-chunk
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, format, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * blockAlign, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitDepth, true);

            // Data sub-chunk
            writeString(view, 36, 'data');
            view.setUint32(40, dataLength, true);

            // Write audio data
            let offset = 44;
            for (let i = 0; i < data.length; i++) {
                view.setInt16(offset, data[i], true);
                offset += 2;
            }

            return arrayBuffer;
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        function testWavExport() {
            const result = document.getElementById('wavResult');
            result.className = 'status info';
            result.textContent = 'Testing WAV export...';

            try {
                if (!testBuffer) {
                    throw new Error('No test buffer available. Run Audio Context test first.');
                }

                const wav = bufferToWave(testBuffer, testBuffer.length);
                const blob = new Blob([wav], { type: 'audio/wav' });
                const url = URL.createObjectURL(blob);
                
                const a = document.createElement('a');
                a.href = url;
                a.download = 'test_sound.wav';
                a.style.display = 'none';
                document.body.appendChild(a);
                a.click();
                
                setTimeout(() => {
                    document.body.removeChild(a);
                    URL.revokeObjectURL(url);
                }, 100);

                result.className = 'status success';
                result.textContent = '‚úÖ WAV file download initiated! Check your downloads folder.';
                
            } catch (error) {
                result.className = 'status error';
                result.textContent = `‚ùå WAV export error: ${error.message}`;
            }
        }

        // Auto-run AudioContext test on load
        window.addEventListener('load', () => {
            setTimeout(testAudioContext, 100);
        });
    </script>
</body>
</html>